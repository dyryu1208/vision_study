{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"computer_vision_4.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1yD--Pg2UcwMWjNV9LzyJG7mpu9moLI0E","authorship_tag":"ABX9TyNjZZmN3FFbbfyxrXht+gDh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Object Detection - Single Shot detection\n","## 실습 : 자율주행 자동차를 위한 SSD7 학습\n","* SSD7 - SSD300의 7층짜리 축소버전"],"metadata":{"id":"MrBiPxd2Oiad"}},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/com_vision_study/ssd')"],"metadata":{"id":"xr9uwhopkKjs"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jUFNmk0L6Cp"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, CSVLogger\n","from tensorflow.keras import backend as K\n","from keras.models import load_model\n","from math import ceil\n","import numpy as np\n","import tensorflow.python.keras.engine\n","\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import Layer, InputSpec\n","\n","from models.keras_ssd7 import build_model\n","from keras_loss_function.keras_ssd_loss import SSDLoss\n","from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n","from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n","from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n","\n","from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n","from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n","\n","from data_generator.object_detection_2d_data_generator import DataGenerator\n","from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n","from data_generator.data_augmentation_chain_variable_input_size import DataAugmentationVariableInputSize\n","from data_generator.data_augmentation_chain_constant_input_size import DataAugmentationConstantInputSize\n","from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation"]},{"cell_type":"code","source":["# Parameters Setting\n","\n","# 입력 이미지 (너비, 높이, 채널)\n","img_height = 300 \n","img_width = 480 \n","img_channels = 3 \n","\n","# Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n","intensity_mean = 127.5 \n","intensity_range = 127.5 \n","\n","# Number of classes in our dataset\n","# 자동차, 트럭, 보행자, 자전거, 신호등\n","n_classes = 5 \n","\n","# 앵커박스 배율 리스트 --> 이 리스트는 min_scale과 max_scale인수값을 상속받음\n","scales = [0.08, 0.16, 0.32, 0.64, 0.96]\n","\n","\n","aspect_ratios = [0.5, 1.0, 2.0] # 앵커박스의 종횡비\n","two_boxes_for_ar1 = True # 종횡비가 1인 앵커박스를 2개 생성할지 여부\n","steps = None # 앵커박스 격자의 이미지 내 시작 위치를 직접 설정할 경우에는 권장하지 않는다.\n","offsets = None # 앵커박스 격자의 간격을 직접 설정할 경우는 권장하지 않는다\n","clip_boxes = False # 앵커 밖으로 빠져나가는 앵커박스를 절단할지 여부\n","variances = [1.0, 1.0, 1.0, 1.0] # 인코딩된 목표 좌표의 배율을 조정할 때 적용할 분산값이 기재된 리스트\n","normalize_coords = True # 이미지 크기에 대한 상대좌표 사용 여부"],"metadata":{"id":"VsPGpllkQVy0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실습 : Udacity 이미지 데이터셋 사용 --> 이미지 크기 480X300\n","#       전체 이미지 22000장\n","\n","K.clear_session()\n","\n","model = build_model(image_size=(img_height, img_width, img_channels),\n","                    n_classes=n_classes,\n","                    mode='training',\n","                    l2_regularization=0.0005,\n","                    scales=scales,\n","                    aspect_ratios_global=aspect_ratios,\n","                    aspect_ratios_per_layer=None,\n","                    two_boxes_for_ar1=two_boxes_for_ar1,\n","                    steps=steps,\n","                    offsets=offsets,\n","                    clip_boxes=clip_boxes,\n","                    variances=variances,\n","                    normalize_coords=normalize_coords,\n","                    subtract_mean=intensity_mean,\n","                    divide_by_stddev=intensity_range\n","                    )\n","\n","adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n","model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"],"metadata":{"id":"ksHCSEzthujC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make Dataset\n","\n","train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n","valid_dataset = DataGenerator(load_images_into_memory=False, hdf_5_dataset_path=None)\n","\n","images_dir = '/content/drive/MyDrive/com_vision_study/ssd/udacity_driving_datasets'\n","\n","train_labels_filename = '/content/drive/MyDrive/com_vision_study/ssd/udacity_driving_datasets/labels_train.csv'\n","valid_labels_filename = '/content/drive/MyDrive/com_vision_study/ssd/udacity_driving_datasets/labels_val.csv'\n","\n","train_dataset.parse_csv(images_dir= images_dir, \n","                        labels_filename=train_labels_filename, \n","                        input_format = ['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n","                        include_classes='all')\n","\n","valid_dataset.parse_csv(images_dir=images_dir, \n","                        labels_filename=train_labels_filename,\n","                        input_format = ['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n","                        include_classes='all')\n","\n","train_dataset_size = train_dataset.get_dataset_size()\n","valid_dataset_size = valid_dataset.get_dataset_size()\n","\n","print(train_dataset_size)\n","print(valid_dataset_size)"],"metadata":{"id":"x01x5vAfd7cs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 16\n","\n","data_augmentation_chain = DataAugmentationConstantInputSize(\n","                              random_brightness = (-48, 48, 0.5),\n","                              random_contrast = (0.5, 1.8, 0.5),\n","                              random_saturation = (0.5, 1.8, 0.5),\n","                              random_hue = (18, 0.5),\n","                              random_flip=0.5,\n","                              random_scale=(0.03, 0.5),\n","                              n_trials_max = 3,\n","                              clip_boxes = True,\n","                              overlap_criterion='area',\n","                              bounds_box_filter = (0.3, 1.0),\n","                              n_boxes_min=1,\n","                              background=(0,0,0)\n","                          )\n","\n","predictor_sizes = [model.get_layer('classes4').output_shape[1:3],\n","                   model.get_layer('classes5').output_shape[1:3],\n","                   model.get_layer('clasess6').output_shape[1:3],\n","                   model.get_layer('classes7').output_shape[1:3]]\n","\n","ssd_input_encoder = SSDInputEncoder(img_height=img_height, \n","                                    img_width=img_width, n_classes=n_classes,\n","                                    predictor_sizes=predictor_sizes,\n","                                    scales=scales,\n","                                    aspect_ratios_global=aspect_ratios,\n","                                    two_boxes_for_ar1=two_boxes_for_ar1,\n","                                    steps=steps,\n","                                    offsets=offsets,\n","                                    clip_boxes=clip_boxes,\n","                                    variances=variances,\n","                                    matching_type='multi',\n","                                    pos_iou_threshold=0.5,\n","                                    neg_iou_limit=0.3,\n","                                    normalize_coords=normalize_coords)\n","\n","\n","\n","# keras fit_generator()함수에 전달할 제너레이터 객체 생성\n","train_generator = train_dataset.generate(batch_size=batch_size, shuffle=True,\n","                                         transformations=[\n","                                                          data_augmentation_chain],\n","                                         label_encoder=ssd_input_encoder,\n","                                         returns={'processed_images', 'encoded_labels'},\n","                                         keep_images_without_gt=False)\n","\n","valid_generator = valid_dataset.generate(batch_size=batch_size, shuffle=False,\n","                                         transformations=[\n","                                                          data_augmentation_chain],\n","                                         label_encoder=ssd_input_encoder,\n","                                         returns={'processed_images', 'encoded_labels'},\n","                                         keep_images_without_gt=False)"],"metadata":{"id":"R0uzLZSje0H_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cp = ModelCheckpoint('ssd7_weights.h5', monitor='val_loss', verbose=1, save_best_only=True,\n","                     save_weights_only=False, mode='auto', period=1)\n","\n","csv_logger = CSVLogger(filname='ssd7_training_log.csv',\n","                       separator=',', append=True)\n","es = EarlyStopping(monito='val_loss', min_delta=0.0, patience=10,\n","                   verbose=1)\n","rp = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, verbose=1,\n","                       epsilon=0.001, cooldown=0, min_lr=0.00001)\n","\n","callbacks = [cp, csv_logger, es, rp]"],"metadata":{"id":"9wYSrCw8tTU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["initial_epoch=0\n","final_epoch=20\n","steps_per_epoch=1000  # 1 epoch 당 가중치 1000번 수정\n","\n","history = model.fit_generator(generator=train_generator, steps_per_epoch=steps_per_epoch,\n","                              epochs=final_epoch, callbacks=callbacks, validation_data=valid_generator,\n","                              validation_steps=ceil(valid_dataset_size/batch_size),\n","                              initial_epoch=initial_epoch)"],"metadata":{"id":"EzyREDgkt86F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(20,12))\n","plt.plot(history.history['loss'], label='loss')\n","plt.plot(history.history['val_loss'], label='val_loss')\n","plt.legend(loc='upper_right', prop={'size' : 24})"],"metadata":{"id":"I-65FY3nvGe3"},"execution_count":null,"outputs":[]}]}